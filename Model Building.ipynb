{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from PostStemmer import PostStemmer\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.base import TransformerMixin\n",
    "#from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first_post = pd.read_json('data/politicos/json/mixed.json')\n",
    "reddit_pos = pd.read_json('data/politicos/json/multi.json')\n",
    "reddit_neg = pd.read_json('data/politicos/json/single.json')\n",
    "first_post = pd.concat([reddit_pos, reddit_neg], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first_post.reset_index(inplace=True)\n",
    "#first_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Author- not needed in analysis, keep for now as index\n",
    "first_post.set_index('author', inplace=True)\n",
    "#first_post.drop('author', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Label / outcome variable\n",
    "multi_post = first_post['total_posts']>1\n",
    "first_post.drop(['total_posts', 'post_ids', 'post_datetimes', 'last_post_datetime'], axis=1, inplace=True)\n",
    "multi_post.index.rename('multi_post', inplace=True)\n",
    "multi_post.name = 'multi_post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Datetimes\n",
    "pdt = pd.to_datetime(first_post['first_post_datetime'])\n",
    "first_post.drop('first_post_datetime', axis=1, inplace=True)\n",
    "\n",
    "# Date == days since Jan 1 2007\n",
    "delta = pdt - pd.Timestamp('01-01-2007')\n",
    "first_post['date'] = delta / np.timedelta64(1, 'D')\n",
    "\n",
    "# Days of week (baseline Monday)\n",
    "first_post['tues']    = pdt.apply(lambda ts: 1 if ts.dayofweek==1 else 0)\n",
    "first_post['wed']     = pdt.apply(lambda ts: 1 if ts.dayofweek==2 else 0)\n",
    "first_post['thurs']   = pdt.apply(lambda ts: 1 if ts.dayofweek==3 else 0)\n",
    "first_post['fri']     = pdt.apply(lambda ts: 1 if ts.dayofweek==4 else 0)\n",
    "first_post['sat']     = pdt.apply(lambda ts: 1 if ts.dayofweek==5 else 0)\n",
    "first_post['sun']     = pdt.apply(lambda ts: 1 if ts.dayofweek==6 else 0)\n",
    "#first_post['weekend'] = pdt.apply(lambda ts: 1 if ts.dayofweek==5 or ts.dayofweek==6 else 0)\n",
    "\n",
    "# Daily and yearly cycles\n",
    "first_post['time_of_day'] = pdt.apply(lambda ts: ts.minute + 60 * ts.hour)\n",
    "first_post['day_of_year'] = pdt.apply(lambda ts: ts.dayofyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ups/downs\n",
    "first_post.rename(columns={'first_post_ups':'ups',\n",
    "                           'first_post_downs':'downs'}, inplace=True)\n",
    "first_post['has_ups'] = first_post['ups'].apply(lambda ups: 1 if ups > 0 else 0)\n",
    "# no downs in this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sentiment\n",
    "sentiment_clf = joblib.load('twitter_sentiment/classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Response sentiment\n",
    "\n",
    "response_sentiment = [] #proportion of responses that were positive\n",
    "#sentiments = []\n",
    "#pos_responses = []\n",
    "#neg_responses = []\n",
    "\n",
    "for i,responses in enumerate(first_post['first_post_responses']):\n",
    "    if isinstance(responses, float): #NaNs due to no responses\n",
    "        #sentiments.append(None)\n",
    "        #pos_responses.append(0)\n",
    "        #neg_responses.append(0)\n",
    "        response_sentiment.append(0)\n",
    "    else: #utf8 encoding for classifier;\n",
    "        responses_utf8 = [response.encode('utf8') for response in responses]\n",
    "        responses_utf8_np = np.array(responses_utf8, ndmin=1)\n",
    "        responses_utf8_np.reshape(responses_utf8_np.shape[0],1) #explicit 1-dimension for classifier\n",
    "        responses_sentiments = sentiment_clf.predict(responses_utf8_np)\n",
    "        #sentiments.append(responses_sentiments)\n",
    "        #pos_responses.append(np.sum(responses_sentiments))\n",
    "        #neg_responses.append(responses_sentiments.shape[0] - np.sum(responses_sentiments))\n",
    "        response_sentiment.append( np.sum(responses_sentiments) / responses_sentiments.shape[0] )\n",
    "\n",
    "first_post['responses_sentiment'] = response_sentiment\n",
    "#first_post['pos_responses'] = pos_responses\n",
    "#first_post['neg_responses'] = neg_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Body sentiment\n",
    "first_post_utf8 = first_post['first_post_body'].apply(lambda post: post.encode('utf8'))\n",
    "first_post['sentiment'] = sentiment_clf.predict(first_post_utf8).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Responses\n",
    "first_post['responses_avg_word_ct'] = first_post['first_post_responses'].apply(lambda responses: 0 if isinstance(responses, float) else np.sum([len(response.split()) for response in responses]) * 1.0 / len(responses) )\n",
    "first_post.rename(columns={'first_post_avg_response_ups':'responses_ups_avg',\n",
    "                           'first_post_avg_response_downs':'responses_downs_avg',\n",
    "                           'first_post_total_responses':'responses_total'}, inplace=True)\n",
    "first_post.drop(['first_post_responses','first_post_response_ups', 'first_post_response_downs'], axis=1, inplace=True) #not doing text analysis for now\n",
    "first_post.fillna(0, inplace=True) #response stats are NaN if no responses\n",
    "# responses_ups_avg is actually an interaction term multiplied by has_responses\n",
    "first_post['has_responses'] = (first_post['responses_total']>0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Body\n",
    "first_post['word_count'] = first_post['first_post_body'].apply(lambda post: len(post.split()))\n",
    "first_post.drop(['first_post_link_id', 'first_post_id', 'first_post_body'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parent type\n",
    "first_post['is_response'] = first_post['parent_type']=='t1'\n",
    "first_post['is_response'] = first_post['is_response'].astype(int)\n",
    "first_post.drop('parent_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downs and Response downs - drop bc no data in this sample\n",
    "first_post.drop('responses_downs_avg', axis=1, inplace=True)\n",
    "first_post.drop('downs', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Const\n",
    "first_post = sm.add_constant(first_post)\n",
    "#first_post['const'] = pd.Series(np.ones(first_post.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>responses_ups_avg</th>\n",
       "      <th>responses_total</th>\n",
       "      <th>ups</th>\n",
       "      <th>date</th>\n",
       "      <th>tues</th>\n",
       "      <th>wed</th>\n",
       "      <th>thurs</th>\n",
       "      <th>fri</th>\n",
       "      <th>sat</th>\n",
       "      <th>...</th>\n",
       "      <th>weekend</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>has_ups</th>\n",
       "      <th>responses_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>responses_avg_word_ct</th>\n",
       "      <th>has_responses</th>\n",
       "      <th>word_count</th>\n",
       "      <th>is_response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_post</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loreat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2123.712963</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1026</td>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alc0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2052.127523</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tyofson</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2119.889931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1281</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Climaximis</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2465.641123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virmundi</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1347.658113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>947</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            const  responses_ups_avg  responses_total  ups         date  tues  \\\n",
       "multi_post                                                                      \n",
       "Loreat          1                  0                0    1  2123.712963     0   \n",
       "alc0            1                  0                0    2  2052.127523     1   \n",
       "tyofson         1                  0                0    1  2119.889931     0   \n",
       "Climaximis      1                  0                0    5  2465.641123     1   \n",
       "virmundi        1                  2                1    0  1347.658113     0   \n",
       "\n",
       "            wed  thurs  fri  sat     ...       weekend  time_of_day  \\\n",
       "multi_post                           ...                              \n",
       "Loreat        1      0    0    0     ...             0         1026   \n",
       "alc0          0      0    0    0     ...             0          183   \n",
       "tyofson       0      0    0    1     ...             1         1281   \n",
       "Climaximis    0      0    0    0     ...             0          923   \n",
       "virmundi      0      1    0    0     ...             0          947   \n",
       "\n",
       "            day_of_year  has_ups  responses_sentiment  sentiment  \\\n",
       "multi_post                                                         \n",
       "Loreat              298        1                    0          0   \n",
       "alc0                227        1                    0          1   \n",
       "tyofson             294        1                    0          0   \n",
       "Climaximis          274        1                    0          0   \n",
       "virmundi            252        0                    0          0   \n",
       "\n",
       "            responses_avg_word_ct  has_responses  word_count  is_response  \n",
       "multi_post                                                                 \n",
       "Loreat                          0              0          46            0  \n",
       "alc0                            0              0          13            1  \n",
       "tyofson                         0              0          10            0  \n",
       "Climaximis                      0              0          16            0  \n",
       "virmundi                      148              1          81            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy [ 0.61094225  0.61094225  0.62068966]\n",
      "precision [ 0.63181818  0.62745098  0.62378378]\n",
      "recall [ 0.95695364  0.9205298   0.93366501]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, max_features=3, max_depth=5)\n",
    "\n",
    "print 'accuracy', cross_val_score(rfc, first_post, multi_post, scoring='accuracy')\n",
    "print 'precision', cross_val_score(rfc, first_post, multi_post, scoring='precision')\n",
    "print 'recall', cross_val_score(rfc, first_post, multi_post, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('date', 0.19850003838149283),\n",
       " ('word_count', 0.13947398578983411),\n",
       " ('has_responses', 0.089742082308330834),\n",
       " ('day_of_year', 0.085063838357629623),\n",
       " ('responses_avg_word_ct', 0.082385990075867194),\n",
       " ('ups', 0.082342064508728635),\n",
       " ('time_of_day', 0.071466010393125445),\n",
       " ('responses_total', 0.064271538782350507),\n",
       " ('is_response', 0.041687624825666188),\n",
       " ('responses_ups_avg', 0.040529674022543254),\n",
       " ('sat', 0.034929555826398097),\n",
       " ('wed', 0.015281767627147025),\n",
       " ('has_ups', 0.015008839507544041),\n",
       " ('sun', 0.014069653937769915),\n",
       " ('sentiment', 0.0077106226529192511),\n",
       " ('tues', 0.0054561662752249922),\n",
       " ('responses_sentiment', 0.0050629877936641445),\n",
       " ('fri', 0.0032906365821672888),\n",
       " ('weekend', 0.0024513200572205463),\n",
       " ('thurs', 0.0012756022943761201),\n",
       " ('const', 0.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(first_post, multi_post)\n",
    "feat_impt = zip(first_post.columns, rfc.feature_importances_)\n",
    "sorted(feat_impt, key=lambda (colname, score): score, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.640985\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>multi_post</td>    <th>  No. Observations:  </th>  <td>  2960</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  2940</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    19</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 16 Aug 2015</td> <th>  Pseudo R-squ.:     </th>  <td>0.04033</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>23:12:03</td>     <th>  Log-Likelihood:    </th> <td> -1897.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -1977.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.194e-24</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                 <td>    1.1709</td> <td>    0.222</td> <td>    5.284</td> <td> 0.000</td> <td>    0.737     1.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>responses_ups_avg</th>     <td>    0.0104</td> <td>    0.015</td> <td>    0.705</td> <td> 0.481</td> <td>   -0.019     0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>responses_total</th>       <td>    0.0068</td> <td>    0.045</td> <td>    0.152</td> <td> 0.879</td> <td>   -0.081     0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ups</th>                   <td>    0.0004</td> <td>    0.003</td> <td>    0.141</td> <td> 0.888</td> <td>   -0.005     0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>date</th>                  <td>   -0.0005</td> <td> 7.21e-05</td> <td>   -7.546</td> <td> 0.000</td> <td>   -0.001    -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tues</th>                  <td>    0.0188</td> <td>    0.142</td> <td>    0.132</td> <td> 0.895</td> <td>   -0.259     0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wed</th>                   <td>    0.0379</td> <td>    0.141</td> <td>    0.268</td> <td> 0.788</td> <td>   -0.239     0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thurs</th>                 <td>   -0.0502</td> <td>    0.141</td> <td>   -0.355</td> <td> 0.722</td> <td>   -0.328     0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fri</th>                   <td>   -0.0743</td> <td>    0.142</td> <td>   -0.523</td> <td> 0.601</td> <td>   -0.352     0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sat</th>                   <td>   -0.3434</td> <td>    0.151</td> <td>   -2.269</td> <td> 0.023</td> <td>   -0.640    -0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sun</th>                   <td>    0.0597</td> <td>    0.151</td> <td>    0.395</td> <td> 0.693</td> <td>   -0.237     0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_of_day</th>           <td>-9.834e-05</td> <td> 8.78e-05</td> <td>   -1.120</td> <td> 0.263</td> <td>   -0.000  7.38e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day_of_year</th>           <td>   -0.0001</td> <td>    0.000</td> <td>   -0.281</td> <td> 0.778</td> <td>   -0.001     0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_ups</th>               <td>    0.0640</td> <td>    0.104</td> <td>    0.615</td> <td> 0.538</td> <td>   -0.140     0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>responses_sentiment</th>   <td>   -0.0215</td> <td>    0.172</td> <td>   -0.125</td> <td> 0.901</td> <td>   -0.358     0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sentiment</th>             <td>   -0.0292</td> <td>    0.086</td> <td>   -0.340</td> <td> 0.734</td> <td>   -0.198     0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>responses_avg_word_ct</th> <td>    0.0028</td> <td>    0.002</td> <td>    1.676</td> <td> 0.094</td> <td>   -0.000     0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_responses</th>         <td>    0.4411</td> <td>    0.132</td> <td>    3.337</td> <td> 0.001</td> <td>    0.182     0.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>word_count</th>            <td>    0.0016</td> <td>    0.001</td> <td>    2.218</td> <td> 0.027</td> <td>    0.000     0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_response</th>           <td>    0.3818</td> <td>    0.081</td> <td>    4.734</td> <td> 0.000</td> <td>    0.224     0.540</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:             multi_post   No. Observations:                 2960\n",
       "Model:                          Logit   Df Residuals:                     2940\n",
       "Method:                           MLE   Df Model:                           19\n",
       "Date:                Sun, 16 Aug 2015   Pseudo R-squ.:                 0.04033\n",
       "Time:                        23:12:03   Log-Likelihood:                -1897.3\n",
       "converged:                       True   LL-Null:                       -1977.1\n",
       "                                        LLR p-value:                 3.194e-24\n",
       "=========================================================================================\n",
       "                            coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "-----------------------------------------------------------------------------------------\n",
       "const                     1.1709      0.222      5.284      0.000         0.737     1.605\n",
       "responses_ups_avg         0.0104      0.015      0.705      0.481        -0.019     0.039\n",
       "responses_total           0.0068      0.045      0.152      0.879        -0.081     0.095\n",
       "ups                       0.0004      0.003      0.141      0.888        -0.005     0.006\n",
       "date                     -0.0005   7.21e-05     -7.546      0.000        -0.001    -0.000\n",
       "tues                      0.0188      0.142      0.132      0.895        -0.259     0.297\n",
       "wed                       0.0379      0.141      0.268      0.788        -0.239     0.315\n",
       "thurs                    -0.0502      0.141     -0.355      0.722        -0.328     0.227\n",
       "fri                      -0.0743      0.142     -0.523      0.601        -0.352     0.204\n",
       "sat                      -0.3434      0.151     -2.269      0.023        -0.640    -0.047\n",
       "sun                       0.0597      0.151      0.395      0.693        -0.237     0.356\n",
       "time_of_day           -9.834e-05   8.78e-05     -1.120      0.263        -0.000  7.38e-05\n",
       "day_of_year              -0.0001      0.000     -0.281      0.778        -0.001     0.001\n",
       "has_ups                   0.0640      0.104      0.615      0.538        -0.140     0.268\n",
       "responses_sentiment      -0.0215      0.172     -0.125      0.901        -0.358     0.315\n",
       "sentiment                -0.0292      0.086     -0.340      0.734        -0.198     0.139\n",
       "responses_avg_word_ct     0.0028      0.002      1.676      0.094        -0.000     0.006\n",
       "has_responses             0.4411      0.132      3.337      0.001         0.182     0.700\n",
       "word_count                0.0016      0.001      2.218      0.027         0.000     0.003\n",
       "is_response               0.3818      0.081      4.734      0.000         0.224     0.540\n",
       "=========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = sm.Logit(multi_post, first_post)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                    3.224882\n",
       "responses_ups_avg        1.010497\n",
       "responses_total          1.006858\n",
       "ups                      1.000397\n",
       "date                     0.999456\n",
       "tues                     1.018970\n",
       "wed                      1.038669\n",
       "thurs                    0.950995\n",
       "fri                      0.928421\n",
       "sat                      0.779701\n",
       "sun                      1.166842\n",
       "weekend                  0.909781\n",
       "time_of_day              0.999902\n",
       "day_of_year              0.999899\n",
       "has_ups                  1.066121\n",
       "responses_sentiment      0.978768\n",
       "sentiment                0.971210\n",
       "responses_avg_word_ct    1.002804\n",
       "has_responses            1.554428\n",
       "word_count               1.001576\n",
       "is_response              1.464895\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3834.6317072757106"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648517\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>multi_post</td>    <th>  No. Observations:  </th>  <td>  2960</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  2953</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 16 Aug 2015</td> <th>  Pseudo R-squ.:     </th>  <td>0.02906</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>23:47:48</td>     <th>  Log-Likelihood:    </th> <td> -1919.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -1977.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.919e-22</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>date</th>                  <td>   -0.0002</td> <td> 4.64e-05</td> <td>   -5.166</td> <td> 0.000</td> <td>   -0.000    -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>word_count</th>            <td>    0.0020</td> <td>    0.001</td> <td>    2.832</td> <td> 0.005</td> <td>    0.001     0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_ups</th>               <td>    0.3446</td> <td>    0.088</td> <td>    3.897</td> <td> 0.000</td> <td>    0.171     0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_responses</th>         <td>    0.5414</td> <td>    0.096</td> <td>    5.612</td> <td> 0.000</td> <td>    0.352     0.730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day_of_year</th>           <td>    0.0007</td> <td>    0.000</td> <td>    1.978</td> <td> 0.048</td> <td> 6.15e-06     0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_response</th>           <td>    0.3846</td> <td>    0.079</td> <td>    4.845</td> <td> 0.000</td> <td>    0.229     0.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>responses_avg_word_ct</th> <td>    0.0026</td> <td>    0.002</td> <td>    1.584</td> <td> 0.113</td> <td>   -0.001     0.006</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:             multi_post   No. Observations:                 2960\n",
       "Model:                          Logit   Df Residuals:                     2953\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Sun, 16 Aug 2015   Pseudo R-squ.:                 0.02906\n",
       "Time:                        23:47:48   Log-Likelihood:                -1919.6\n",
       "converged:                       True   LL-Null:                       -1977.1\n",
       "                                        LLR p-value:                 1.919e-22\n",
       "=========================================================================================\n",
       "                            coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "-----------------------------------------------------------------------------------------\n",
       "date                     -0.0002   4.64e-05     -5.166      0.000        -0.000    -0.000\n",
       "word_count                0.0020      0.001      2.832      0.005         0.001     0.003\n",
       "has_ups                   0.3446      0.088      3.897      0.000         0.171     0.518\n",
       "has_responses             0.5414      0.096      5.612      0.000         0.352     0.730\n",
       "day_of_year               0.0007      0.000      1.978      0.048      6.15e-06     0.001\n",
       "is_response               0.3846      0.079      4.845      0.000         0.229     0.540\n",
       "responses_avg_word_ct     0.0026      0.002      1.584      0.113        -0.001     0.006\n",
       "=========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit2 = sm.Logit(multi_post, first_post[[  'date',\n",
    "                                            'word_count', \n",
    "                                            'has_ups', \n",
    "                                            'has_responses', \n",
    "                                            'day_of_year', \n",
    "                                            #'time_of_day', \n",
    "                                            #'responses_ups_avg', \n",
    "                                            'is_response', \n",
    "                                            'responses_avg_word_ct']])\n",
    "result2 = logit2.fit()\n",
    "result2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3853.2188066988238"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert word counts to 10-word counts \n",
    "result2_params = result2.params.copy()\n",
    "result2_params['responses_avg_word_ct'] = result2_params['responses_avg_word_ct'] *10\n",
    "result2_params['word_count'] = result2_params['word_count'] *10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Odds Ratio</th>\n",
       "      <th>P-val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>has_responses</th>\n",
       "      <td>1.7184</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_response</th>\n",
       "      <td>1.4691</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_ups</th>\n",
       "      <td>1.4114</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responses_avg_word_ct</th>\n",
       "      <td>1.0265</td>\n",
       "      <td>0.1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>1.0207</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_year</th>\n",
       "      <td>1.0007</td>\n",
       "      <td>0.0479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Odds Ratio  P-val\n",
       "has_responses              1.7184 0.0000\n",
       "is_response                1.4691 0.0000\n",
       "has_ups                    1.4114 0.0001\n",
       "responses_avg_word_ct      1.0265 0.1133\n",
       "word_count                 1.0207 0.0046\n",
       "day_of_year                1.0007 0.0479\n",
       "date                       0.9998 0.0000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_pvals = pd.concat([np.exp(result2_params), result2.pvalues], axis=1)\n",
    "odds_pvals.columns = ['Odds Ratio', 'P-val']\n",
    "odds_pvals.sort('Odds Ratio', ascending=False, inplace=True)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "odds_pvals\n",
    "# note these are odds ratios for 10-word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result2.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting feedback on first posts is associated with posting again in Reddit Politics.\n",
    "- Receiving at least one response to first comment associated with 71% better odds of posting again (p &lt; 0.001)\n",
    "- Receiving at least one upvote to first comment associated with 41% better odds of posting again (p &lt; 0.001)\n",
    "    \n",
    "Participating in dialog was also associated with posting again. Users whose first comment was in response to another comment had 47% better odds of posting again (p &lt; 0.001). (This was after controlling for similar number of responses and upvotes, so it's not because responding to others makes them more likely to get responses in return.)\n",
    "\n",
    "Length of first comments and responses to first comments were somewhat associated with higher probability of posting again, although the effect size was smaller and statistical significance was weaker. For each additional 10 words in their first comment, users had 2.1% higher odds of posting again (p=0.005). For each additional 10 words on average in the responses to their first comment, users had 2.7% higher odds of posting again, although the result was not statistically significant (p=0.113).\n",
    "\n",
    "All results were controlled for yearly seasonality, and absolute date across site history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_responses            1.640937\n",
      "is_response              1.512106\n",
      "responses_ups_avg        1.009108\n",
      "responses_avg_word_ct    1.002661\n",
      "word_count               1.002130\n",
      "ups                      1.001295\n",
      "day_of_year              1.000861\n",
      "time_of_day              1.000131\n",
      "date                     0.999824\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "odds_ratios = np.exp(result2.params).sort(ascending=False, inplace=False)\n",
    "print odds_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = first_post[[ 'date',\n",
    "                        'word_count', \n",
    "                        'ups', \n",
    "                        'has_responses', \n",
    "                        'day_of_year', \n",
    "                        'time_of_day', \n",
    "                        'responses_ups_avg', \n",
    "                        'is_response', \n",
    "                        'responses_avg_word_ct' ]]\n",
    "sk_logit = LogisticRegression(fit_intercept=False)\n",
    "accuracy_cv = cross_val_score(sk_logit, X=features, y=multi_post, scoring='accuracy', cv=5)\n",
    "print 'model accuracy', np.mean(accuracy_cv)\n",
    "auc_cv = cross_val_score(sk_logit, X=features, y=m\n",
    "                         ulti_post, scoring='roc_auc', cv=5)\n",
    "print 'model auc', np.mean(auc_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0e065e092f4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result3' is not defined"
     ]
    }
   ],
   "source": [
    "np.exp(result3.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yahoo Answers study, which included first-week engagement:\n",
    "```\n",
    "model accuracy: 0.691\n",
    "model auc: 0.758\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sk_dummy = DummyClassifier()\n",
    "accuracy_cv = cross_val_score(sk_dummy, X=features, y=multi_post, scoring='accuracy', cv=5)\n",
    "print 'model accuracy', np.mean(accuracy_cv)\n",
    "auc_cv = cross_val_score(sk_dummy, X=features, y=multi_post, scoring='roc_auc', cv=5)\n",
    "print 'model auc', np.mean(auc_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression model predicts ~20% more accurately than random guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit3 = sm.Logit(multi_post, first_post[[  'date',\n",
    "                                            'word_count', \n",
    "                                            #'ups', \n",
    "                                            'has_responses', \n",
    "                                            'day_of_year', \n",
    "                                            'time_of_day', \n",
    "                                            #'responses_ups_avg', \n",
    "                                            'is_response', \n",
    "                                            'responses_avg_word_ct' ]])\n",
    "result3 = logit3.fit()\n",
    "result3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result3.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_crosstab_scaled = response_crosstab / response_crosstab.sum(axis=0)\n",
    "response_crosstab_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_crosstab_scaled.T.plot(kind=\"bar\", stacked=True)\n",
    "plt.title('Proportion who commented again,\\n depending on whether or not they \\nreceived a response to their first comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_post.word_count.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(first_post[first_post['ups']>0]['ups'], bins=75)\n",
    "plt.xlim((0,80))\n",
    "plt.title('Upvote distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_discrete = pd.cut(first_post.word_count, [0,50,100,150,200,800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_crosstab = pd.crosstab(multi_post, word_count_discrete)\n",
    "word_count_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_crosstab_scaled = word_count_crosstab / word_count_crosstab.sum(axis=0)\n",
    "word_count_crosstab_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_count_crosstab_scaled.T.plot(kind=\"bar\", stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More responses to mid-length comments -- consider feature for mid-length comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_post.ups.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ups_discrete = pd.cut(first_post.ups, [-100,-0.5,0.5,10,100,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ups_crosstab = pd.crosstab(multi_post, ups_discrete)\n",
    "ups_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ups_crosstab_scaled = ups_crosstab / ups_crosstab.sum(axis=0)\n",
    "ups_crosstab_scaled.T.plot(kind=\"bar\", stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly upvoted first_post more likely to repost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are ups and has_responses collinear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ups_vs_has_responses = pd.crosstab(ups_discrete, first_post.has_responses)\n",
    "ups_vs_has_responses.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ups_vs_has_responses_scaled = ups_vs_has_responses.T / ups_vs_has_responses.sum(axis=1)\n",
    "ups_vs_has_responses_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ups_vs_has_responses_scaled.T.plot(kind=\"bar\", stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_post.apply(np.log).plot('ups','responses_total', kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More upvotes is correlated with having responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
